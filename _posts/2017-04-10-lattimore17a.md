---
title: The End of Optimism? An Asymptotic Analysis of Finite-Armed Linear Bandits
abstract: 'Stochastic linear bandits are a natural and simple generalisation of finite-armed
  bandits with numerous practical applications. Current approaches focus on generalising
  existing techniques for finite-armed bandits, notably the otimism principle and
  Thompson sampling. Prior analysis has mostly focussed on the worst-case setting.
  We analyse the asymptotic regret and show matching upper and lower bounds on what
  is achievable. Surprisingly, our results show that no algorithm based on optimism
  or Thompson sampling will ever achieve the optimal rate. In fact, they can be arbitrarily
  far from optimal, even in very simple cases. This is a disturbing result because
  these techniques are standard tools that are widely used for sequential optimisation,
  for example,  generalised linear bandits and reinforcement learning. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: lattimore17a
month: 0
tex_title: "{The End of Optimism? An Asymptotic Analysis of Finite-Armed Linear Bandits}"
firstpage: 728
lastpage: 737
page: 728-737
order: 728
cycles: false
author:
- given: Tor
  family: Lattimore
- given: Csaba
  family: Szepesvari
date: 2017-04-10
address: 
publisher: PMLR
container-title: Proceedings of the 20th International Conference on Artificial Intelligence
  and Statistics
volume: '54'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 4
  - 10
pdf: http://proceedings.mlr.press/v54/lattimore17a/lattimore17a.pdf
extras:
- label: Supplementary pdf
  link: http://proceedings.mlr.press/v54/lattimore17a/lattimore17a/lattimore17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
