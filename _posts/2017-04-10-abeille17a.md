---
title: Linear Thompson Sampling Revisited
abstract: We derive an alternative proof for the regret of Thompson sampling (TS)
  in the stochastic linear bandit setting. While we obtain a regret bound of order
  $O(d^3/2\sqrtT)$ as in previous results, the proof sheds new light on the functioning
  of the TS. We leverage on the structure of the problem to show how the regret is
  related to the sensitivity (i.e., the gradient) of the objective function and how
  selecting optimal arms associated to \textitoptimistic parameters does control it.
  Thus we show that TS can be seen as a generic randomized algorithm where the sampling
  distribution is designed to have a fixed probability of being optimistic, at the
  cost of an additional $\sqrtd$ regret factor compared to a UCB-like approach. Furthermore,
  we show that our proof can be readily applied to regularized linear optimization
  and generalized linear model problems.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: abeille17a
month: 0
tex_title: "{Linear Thompson Sampling Revisited}"
firstpage: 176
lastpage: 184
page: 176-184
order: 176
cycles: false
author:
- given: Marc
  family: Abeille
- given: Alessandro
  family: Lazaric
date: 2017-04-10
address: 
publisher: PMLR
container-title: Proceedings of the 20th International Conference on Artificial Intelligence
  and Statistics
volume: '54'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 4
  - 10
pdf: http://proceedings.mlr.press/v54/abeille17a/abeille17a.pdf
extras:
- label: Supplementary pdf
  link: http://proceedings.mlr.press/v54/abeille17a/abeille17a/abeille17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
