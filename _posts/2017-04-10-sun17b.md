---
title: Learning Structured Weight Uncertainty in Bayesian Neural Networks
abstract: Deep neural networks (DNNs) are increasingly popular in modern machine learning.
  Bayesian learning affords the opportunity to quantify posterior uncertainty on DNN
  model parameters. Most existing work adopts independent Gaussian priors on the model
  weights, ignoring possible structural information. In this paper, we consider the
  matrix variate Gaussian (MVG) distribution to model structured correlations within
  the weights of a DNN. To make posterior inference feasible, a reparametrization
  is proposed for the MVG prior, simplifying the complex MVG-based model to an equivalent
  yet simpler model with independent Gaussian priors on the transformed weights. Consequently,
  we develop a scalable Bayesian online inference algorithm by adopting the recently
  proposed probabilistic backpropagation framework. Experiments on several synthetic
  and real datasets indicate the superiority of our model, achieving competitive performance
  in terms of model likelihood and predictive root mean square error. Importantly,
  it also yields faster convergence speed compared to related Bayesian DNN models.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: sun17b
month: 0
tex_title: "{Learning Structured Weight Uncertainty in Bayesian Neural Networks}"
firstpage: 1283
lastpage: 1292
page: 1283-1292
order: 1283
cycles: false
author:
- given: Shengyang
  family: Sun
- given: Changyou
  family: Chen
- given: Lawrence
  family: Carin
date: 2017-04-10
address: 
publisher: PMLR
container-title: Proceedings of the 20th International Conference on Artificial Intelligence
  and Statistics
volume: '54'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 4
  - 10
pdf: http://proceedings.mlr.press/v54/sun17b/sun17b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v54/sun17b/sun17b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
