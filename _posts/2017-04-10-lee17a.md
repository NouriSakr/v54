---
title: Hierarchically-partitioned Gaussian Process Approximation
abstract: The Gaussian process (GP) is a simple yet powerful probabilistic framework
  for various machine learning tasks.  However, exact algorithms for learning and
  prediction are prohibitive to be applied to large datasets due to inherent computational
  complexity. To overcome this main limitation, various techniques have been proposed,
  and in particular, local GP algorithms that scales “truly linearly”  with respect
  to the dataset size. In this paper, we introduce a hierarchical model based on local
  GP for large-scale datasets, which stacks inducing points over inducing points in
  layers. By using different kernels in each layer, the overall model becomes multi-scale
  and is able to capture both long- and short-range dependencies.  We demonstrate
  the effectiveness of our model by speed-accuracy performance on challenging real-world
  datasets.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: lee17a
month: 0
tex_title: "{Hierarchically-partitioned Gaussian Process Approximation}"
firstpage: 822
lastpage: 831
page: 822-831
order: 822
cycles: false
author:
- given: Byung-Jun
  family: Lee
- given: Jongmin
  family: Lee
- given: Kee-Eung
  family: Kim
date: 2017-04-10
address: 
publisher: PMLR
container-title: Proceedings of the 20th International Conference on Artificial Intelligence
  and Statistics
volume: '54'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 4
  - 10
pdf: http://proceedings.mlr.press/v54/lee17a/lee17a.pdf
extras:
- label: Supplementary pdf
  link: http://proceedings.mlr.press/v54/lee17a/lee17a/lee17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
