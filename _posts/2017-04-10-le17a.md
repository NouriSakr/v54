---
title: Inference Compilation and Universal Probabilistic Programming
abstract: We introduce a method for using  deep neural networks to amortize the cost
  of inference in models from the family induced by universal probabilistic programming
  languages, establishing a framework that combines the strengths of probabilistic
  programming and deep learning methods.  We call what we do “compilation of inference”
  because our method transforms a denotational specification of an inference problem
  in the form of a probabilistic program written in a universal programming language
  into a trained neural network denoted in a neural network specification language.  When
  at test time this neural network is fed observational data and executed, it performs
  approximate inference in the original model specified by the probabilistic program.  Our
  training objective and learning procedure are designed to allow the trained neural
  network to be used as a proposal distribution in a sequential importance sampling
  inference engine.  We illustrate our method on mixture models and Captcha solving
  and show significant speedups in the efficiency of inference.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: le17a
month: 0
tex_title: "{Inference Compilation and Universal Probabilistic Programming}"
firstpage: 1338
lastpage: 1348
page: 1338-1348
order: 1338
cycles: false
author:
- given: Tuan Anh
  family: Le
- given: Atilim Gunes
  family: Baydin
- given: Frank
  family: Wood
date: 2017-04-10
address: 
publisher: PMLR
container-title: Proceedings of the 20th International Conference on Artificial Intelligence
  and Statistics
volume: '54'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 4
  - 10
pdf: http://proceedings.mlr.press/v54/le17a/le17a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
