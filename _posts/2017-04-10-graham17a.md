---
title: Asymptotically exact inference in differentiable generative models
abstract: Many generative models can be expressed as a differentiable function of
  random inputs drawn from some simple probability density. This framework includes
  both deep generative architectures such as Variational Autoencoders and a large
  class of procedurally defined simulator models. We present a method for performing
  efficient MCMC inference in such models when conditioning on observations of the
  model output. For some models this offers an asymptotically exact inference method
  where Approximate Bayesian Computation might otherwise be employed. We use the intuition
  that inference corresponds to integrating a density across the manifold corresponding
  to the set of inputs consistent with the observed outputs. This motivates the use
  of a constrained variant of Hamiltonian Monte Carlo which leverages the smooth geometry
  of the manifold to coherently move between inputs exactly consistent with observations.
  We validate the method by performing inference tasks in a diverse set of models.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: graham17a
month: 0
tex_title: "{Asymptotically exact inference in differentiable generative models}"
firstpage: 499
lastpage: 508
page: 499-508
order: 499
cycles: false
author:
- given: Matthew
  family: Graham
- given: Amos
  family: Storkey
date: 2017-04-10
address: 
publisher: PMLR
container-title: Proceedings of the 20th International Conference on Artificial Intelligence
  and Statistics
volume: '54'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 4
  - 10
pdf: http://proceedings.mlr.press/v54/graham17a/graham17a.pdf
extras:
- label: Supplementary pdf
  link: http://proceedings.mlr.press/v54/graham17a/graham17a/graham17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
