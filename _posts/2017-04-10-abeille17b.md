---
title: Thompson Sampling for Linear-Quadratic Control Problems
abstract: We consider the exploration-exploitation tradeoff in linear quadratic (LQ)
  control problems, where the state dynamics is linear and the cost function is quadratic
  in states and controls. We analyze the regret of Thompson sampling (TS) (a.k.a.
  posterior-sampling for reinforcement learning) in the frequentist setting, i.e.,
  when the parameters characterizing the LQ dynamics are fixed. Despite the empirical
  and theoretical success in a wide range of problems from multi-armed bandit to linear
  bandit, we show that when studying the frequentist regret TS in control problems,
  we need to trade-off the frequency of sampling optimistic parameters and the frequency
  of switches in the control policy. This results in an overall regret of $O(T^2/3)$,
  which is significantly worse than the regret $O(\sqrtT)$ achieved by the optimism-in-face-of-uncertainty
  algorithm in LQ control problems.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: abeille17b
month: 0
tex_title: "{Thompson Sampling for Linear-Quadratic Control Problems}"
firstpage: 1246
lastpage: 1254
page: 1246-1254
order: 1246
cycles: false
author:
- given: Marc
  family: Abeille
- given: Alessandro
  family: Lazaric
date: 2017-04-10
address: 
publisher: PMLR
container-title: Proceedings of the 20th International Conference on Artificial Intelligence
  and Statistics
volume: '54'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 4
  - 10
pdf: http://proceedings.mlr.press/v54/abeille17b/abeille17b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v54/abeille17b/abeille17b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
