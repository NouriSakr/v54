---
title: 'Less than a Single Pass: Stochastically Controlled Stochastic Gradient'
abstract: We develop and analyze a procedure for gradient-based optimization that
  we refer to as stochastically controlled stochastic gradient (SCSG). As a member
  of the SVRG family of algorithms, SCSG makes use of gradient estimates at two scales.
  Unlike most existing algorithms in this family, both the computation cost and the
  communication cost of SCSG do not necessarily scale linearly with the sample size
  n; indeed, these costs are independent of n when the target accuracy is small. An
  experimental evaluation of SCSG on the MNIST dataset shows that it can yield accurate
  results on this dataset on a single commodity machine with a memory footprint of
  only 2.6MB and only eight disk accesses.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: lei17a
month: 0
tex_title: "{Less than a Single Pass: Stochastically Controlled Stochastic Gradient}"
firstpage: 148
lastpage: 156
page: 148-156
order: 148
cycles: false
author:
- given: Lihua
  family: Lei
- given: Michael
  family: Jordan
date: 2017-04-10
address: 
publisher: PMLR
container-title: Proceedings of the 20th International Conference on Artificial Intelligence
  and Statistics
volume: '54'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 4
  - 10
pdf: http://proceedings.mlr.press/v54/lei17a/lei17a.pdf
extras:
- label: Supplementary pdf
  link: http://proceedings.mlr.press/v54/lei17a/lei17a/lei17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
