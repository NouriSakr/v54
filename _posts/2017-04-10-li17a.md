---
title: Minimax Gaussian Classification & Clustering
abstract: 'We present minimax bounds for classification and clustering error in the
  setting where covariates are drawn from a mixture of two isotropic Gaussian distributions.
  Here, we define clustering error in a  discriminative fashion, demonstrating fundamental
  connections between classification (supervised) and clustering (unsupervised). For
  both classification and clustering, our lower bounds show that without enough samples,
  the best any classifier or clustering rule can do is close to random guessing. For
  classification, as part of our upper bound analysis,  we show that Fisherâ€™s linear
  discriminant achieves a fast minimax rate Theta(1/n) with enough samples n. For
  clustering, as part of our upper bound analysis, we show that a clustering rule
  constructed using principal component analysis achieves the minimax rate with enough
  samples. We also provide lower and upper bounds for the high-dimensional sparse  setting
  where the dimensionality of the covariates p is potentially larger than the number
  of samples n, but where the difference between the Gaussian means is sparse. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: li17a
month: 0
tex_title: "{Minimax Gaussian Classification & Clustering}"
firstpage: 1
lastpage: 9
page: 1-9
order: 1
cycles: false
author:
- given: Tianyang
  family: Li
- given: Xinyang
  family: Yi
- given: Constantine
  family: Carmanis
- given: Pradeep
  family: Ravikumar
date: 2017-04-10
address: 
publisher: PMLR
container-title: Proceedings of the 20th International Conference on Artificial Intelligence
  and Statistics
volume: '54'
genre: inproceedings
issued:
  date-parts:
  - 2017
  - 4
  - 10
pdf: http://proceedings.mlr.press/v54/li17a/li17a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v54/li17a/li17a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
